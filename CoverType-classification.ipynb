{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of cover types \n",
    "In this project there will be created a model using deep learning to predict forest cover type (the most common kind of tree cover) based only on cartographic variables. The actual forest cover type for a given 30 x 30 meter cell was determined from US Forest Service (USFS) Region 2 Resource Information System data. The cover types we are going to predict are the following:\n",
    "\n",
    "- Spruce/Fir\n",
    "- Lodgepole Pine\n",
    "- Ponderosa Pine\n",
    "- Cottonwood/Willow\n",
    "- Aspen\n",
    "- Douglas-fir\n",
    "- Krummholz\n",
    "\n",
    "The project will use a deeplearning model created with `Tensorflow` and `Keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow\timport keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Python: {}'.format(sys.version))  # Python version\n",
    "print('numpy: {}'.format(np.__version__))  # Numpy version\n",
    "print('pandas: {}'.format(pd.__version__))  # Pandas version\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))  # Matplotlib version\n",
    "print('sklearn: {}'.format(sklearn.__version__))  # sklearn version\n",
    "print('tensorflow: {}'.format(tf.__version__))  # tensorflow\n",
    "print('seaborn: {}'.format(sns.__version__))  # seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess and explore the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
       "0                                6279  ...            0            0   \n",
       "1                                6225  ...            0            0   \n",
       "2                                6121  ...            0            0   \n",
       "3                                6211  ...            0            0   \n",
       "4                                6172  ...            0            0   \n",
       "\n",
       "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type39  Soil_Type40  class  \n",
       "0            0            0      5  \n",
       "1            0            0      5  \n",
       "2            0            0      2  \n",
       "3            0            0      2  \n",
       "4            0            0      5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cover_data.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of dataset\n",
    "\n",
    "In the dataset there are 55 columns, the last one `Class_type` is the label column (meaning the one we want to predict). The other 54 columns consists of both numerical and categorical attributes. Columns 0-10 are numerical, while 11-54 are categorical. Below one can see an explanation of the different columns. This information can be found at [Kaggle](https://www.kaggle.com/uciml/forest-cover-type-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature Name | Names |\n",
    "| ------------ | ----- |\n",
    "| Wilderness_Area1 | Rawah Wilderness Area |\n",
    "| Wilderness_Area2 | Neota Wilderness Area |\n",
    "| Wilderness_Area3 | Comanche Wilderness Area |\n",
    "| Wilderness_Area4 | Cache La Poudre Wilderness Area |\n",
    "| Soil_Type1 | Cathedral family - Rock outcrop complex, extremely stony |\n",
    "| Soil_Type2 | Vanet - Ratake families complex, very stony |\n",
    "| Soil_Type3 | Haploborolis - Rock outcrop complex, rubbly |\n",
    "| Soil_Type4 | Ratake family - Rock outcrop complex, rubbly |\n",
    "| Soil_Type5 | Vanet family - Rock outcrop complex, rubbly |\n",
    "| Soil_Type6 | Vanet - Wetmore families - Rock outcrop complex, stony |\n",
    "| Soil_Type7 | Gothic family |\n",
    "| Soil_Type8 | Supervisor - Limber families complex |\n",
    "| Soil_Type9 | Troutville family, very stony |\n",
    "| Soil_Type10 | Bullwark - Catamount families - Rock outcrop complex, rubbly |\n",
    "| Soil_Type11 | Bullwark - Catamount families - Rock land complex, rubbly |\n",
    "| Soil_Type12 | Legault family - Rock land complex, stony |\n",
    "| Soil_Type13 | Catamount family - Rock land - Bullwark family complex, rubbly |\n",
    "| Soil_Type14 | Pachic Argiborolis - Aquolis complex |\n",
    "| Soil_Type15 | _unspecified in the USFS Soil and ELU Survey_ |\n",
    "| Soil_Type16 | Cryaquolis - Cryoborolis complex |\n",
    "| Soil_Type17 | Gateview family - Cryaquolis complex |\n",
    "| Soil_Type18 | Rogert family, very stony |\n",
    "| Soil_Type19 | Typic Cryaquolis - Borohemists complex |\n",
    "| Soil_Type20 | Typic Cryaquepts - Typic Cryaquolls complex |\n",
    "| Soil_Type21 | Typic Cryaquolls - Leighcan family, till substratum complex |\n",
    "| Soil_Type22 | Leighcan family, till substratum, extremely bouldery |\n",
    "| Soil_Type23 | Leighcan family, till substratum, - Typic Cryaquolls complex. |\n",
    "| Soil_Type24 | Leighcan family, extremely stony |\n",
    "| Soil_Type25 | Leighcan family, warm, extremely stony |\n",
    "| Soil_Type26 | Granile - Catamount families complex, very stony |\n",
    "| Soil_Type27 | Leighcan family, warm - Rock outcrop complex, extremely stony |\n",
    "| Soil_Type28 | Leighcan family - Rock outcrop complex, extremely stony |\n",
    "| Soil_Type29 | Como - Legault families complex, extremely stony |\n",
    "| Soil_Type30 | Como family - Rock land - Legault family complex, extremely stony |\n",
    "| Soil_Type31 | Leighcan - Catamount families complex, extremely stony |\n",
    "| Soil_Type32 | Catamount family - Rock outcrop - Leighcan family complex, extremely stony |\n",
    "| Soil_Type33 | Leighcan - Catamount families - Rock outcrop complex, extremely stony |\n",
    "| Soil_Type34 | Cryorthents - Rock land complex, extremely stony |\n",
    "| Soil_Type35 | Cryumbrepts - Rock outcrop - Cryaquepts complex |\n",
    "| Soil_Type36 | Bross family - Rock land - Cryumbrepts complex, extremely stony |\n",
    "| Soil_Type37 | Rock outcrop - Cryumbrepts - Cryorthents complex, extremely stony |\n",
    "| Soil_Type38 | Leighcan - Moran families - Cryaquolls complex, extremely stony |\n",
    "| Soil_Type39 | Moran family - Cryorthents - Leighcan family complex, extremely stony |\n",
    "| Soil_Type40 | Moran family - Cryorthents - Rock land complex, extremely stony |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = df.shape\n",
    "print('We have ', x, ' number of observations and ', y-1, ' features for this dataset to predict type of forest cover.')\n",
    "\n",
    "dict_count = Counter(df['class'])\n",
    "\n",
    "for x in dict_count :\n",
    "    print(f\"Cover type {x} has {dict_count[x]} rows in data set\")\n",
    "print(f\"This means there are {len(dict_count)} classes to predict\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes/cover types has these keys:\n",
    "\n",
    "| Key | Name                 |  Count |\n",
    "|-----|----------------------|--------|\n",
    "| 1   | Spruce / Fir         | 211840 |\n",
    "| 2   | Lodgepole Pine       | 283301 |\n",
    "| 3   | Ponderosa Pine       |  35754 |\n",
    "| 4   | Cottonwood / Willow  |  2747  |\n",
    "| 5   | Aspen                |  9493  |\n",
    "| 6   | Douglas-fir          | 17367  |\n",
    "| 7   | Krummholz            | 20510  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets look even more closely at the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the table we see that all rows are numeric integers, so there is no need for converstions. We can also notice that every row has a non-null value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = df.iloc[:, :10]\n",
    "numerical_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean: By looking at the mean value we see that it varies from column `Slope` at value 14  and all the way up to 2959 which belongs to `Elevation`. \n",
    "- Standard deviation: Describes how much each column deviates from its mean, so basically how much the data varies for a given column. The most spread out column is `Horizontal_Distance_To_Roadways`. The most dense column is `Slope`.\n",
    "- Min: All of the attributes has a minimum value of 0, except from `Elevation` and `Vertical_Distance_To_Hydrology`. \n",
    "\n",
    "We can also see that the only numerical columns are: `Elevation`, `Aspect`, `Slop`, `Horizontal_Distance_To_Roadways`, `Vertical_Distance_To_Hydrology`, `Hillside_9am`, `Hillshade_Noon`, `Hillshade_3pm`,\t`Horizontal_Distance_To_Fire_Points`. Meaning the 10 first columns in the data set. We can plot the numerical spread of these features. The rest of the columns are categorical. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = matplotlib.pyplot\n",
    "\n",
    "# plot bg\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "#Size of the plot\n",
    "plt.subplots(figsize=(21, 14))\n",
    "\n",
    "# setting color of the plot\n",
    "color = sns.color_palette('pastel')\n",
    "\n",
    "# Using seaborn to plot it horizontally with 'color'\n",
    "sns.boxplot(data = numerical_features, orient='h', palette=color)\n",
    "\n",
    "# Title of the graph\n",
    "plt.title('Spread of data in Numerical Features', size = 20)\n",
    "\n",
    "# Horizontal axis Label\n",
    "plt.xlabel('Observations', size = 17)\n",
    "# Vertical axis Label\n",
    "plt.ylabel('Features', size = 17)\n",
    "\n",
    "# x-axis label size\n",
    "plt.xticks(size = 17)\n",
    "#y-axis label size\n",
    "plt.yticks(size = 15)\n",
    "\n",
    "# display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features\n",
    "\n",
    "There are two types of categorical features: \n",
    "- `Wilderness_AreaX` \n",
    "- `Soil_typeX`\n",
    "\n",
    "In this section there will be a description of these two features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = df.iloc[:, 10:-1]\n",
    "\n",
    "# Splitting the features \n",
    "wild_df, soil_df = categorical_features.iloc[:,:4], categorical_features.iloc[:,4:]\n",
    "# Describing the categorical features\n",
    "categorical_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style({'grid.color': 'white'})\n",
    "\n",
    "\n",
    "# Sum the data, plot bar with given size using color defined\n",
    "wild_df.sum().plot(kind='bar', figsize=(10, 8), color='#A40E4C')\n",
    "\n",
    "# Title of the graph\n",
    "plt.title('No. of observations of Wilderness Areas', size = 20)\n",
    "\n",
    "# Horizontal axis Label\n",
    "plt.xlabel('Wilderness Areas', size = 17)\n",
    "# Vertical axis Label\n",
    "plt.ylabel('No.of Observation', size = 17)\n",
    "\n",
    "# x-axis label size, setting label rotations\n",
    "plt.xticks(rotation = 'horizontal', size = 14)\n",
    "# y-axis label size\n",
    "plt.yticks(size = 14)\n",
    "\n",
    "# removing the top and right axes spines, which are not needed\n",
    "sns.despine()\n",
    "\n",
    "# display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see most of the data belongs to `Wilderness_Area1` and `Wilderness_Area3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background style\n",
    "sns.set_style({'grid.color': 'white'})\n",
    "\n",
    "# Sum the data, plot horizontal bar with given size using color defined\n",
    "soil_df.sum().plot(kind='bar', figsize=(24, 12), color='#A40E4C')\n",
    "\n",
    "# Title of the graph\n",
    "plt.title('No. of observations of Soil Types', size = 20)\n",
    "\n",
    "# Horizontal axis Label\n",
    "plt.xlabel('Soil Types', size = 20)\n",
    "# Vertical axis Label\n",
    "plt.ylabel('Observations', size = 20)\n",
    "\n",
    "# X-axis label size, setting label rotations\n",
    "plt.xticks(rotation = 90, size = 15)\n",
    "# Y-axis label size\n",
    "plt.yticks(size = 15)\n",
    "\n",
    "# Display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here most of the rows in the columns has the `Soil_Type29`. Which is Como - Legault families complex, extremely stony."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid color\n",
    "sns.set_style({'grid.color': 'white'})\n",
    "\n",
    "# Sum soil_df values, and pass it as a series \n",
    "soil_sum = pd.Series(soil_df.sum())\n",
    "\n",
    "# Sort the values in descending order\n",
    "soil_sum.sort_values(ascending = False, inplace = True)\n",
    "\n",
    "# Plot horizontal bar with given size using color defined\n",
    "soil_sum.plot(kind='barh', figsize=(23, 17), color= '#A40E4C')\n",
    "\n",
    "# Horizontal bar flips columns in ascending order, this will filp it back in descending order\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Title of the graph\n",
    "plt.title('No. of observations of Soil Types', size = 20)\n",
    "\n",
    "# Horizontal axis Label\n",
    "plt.xlabel('No.of Observation', size = 17)\n",
    "# Vertical axis Label\n",
    "plt.ylabel('Soil Types', size = 17)\n",
    "\n",
    "# X-axis label\n",
    "plt.xticks(rotation = 'horizontal', size = 15)\n",
    "# Y-axis label \n",
    "plt.yticks(size = 16)\n",
    "\n",
    "# Display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Soil_Type15` has the fewest numbers of observations, while the most observed is `Soil_Type29`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violin plots\n",
    "Here I will be comparing each feature in the data to the target variable. This will visualize the density and the distribution of each target variable's class in comparison to each feature. I will begin with the numerical features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = numerical_features.columns\n",
    "target = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def violinPlot(column,data,features):\n",
    "    #figure size\n",
    "    plt.subplots(figsize=(16, 11))\n",
    "    \n",
    "    # Plot violin for column\n",
    "    sns.violinplot(data=data, x=target, y = features[column])\n",
    "    \n",
    "    # x-axis label size\n",
    "    plt.xticks(size = 15)\n",
    "    # y-axis label size\n",
    "    plt.yticks(size = 16)\n",
    "\n",
    "    # Horizontal axis Label\n",
    "    plt.xlabel('Forest Cover Types', size = 17)\n",
    "    # Vertical axis Label\n",
    "    plt.ylabel(features[column], size = 17)\n",
    "  \n",
    "    # display plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(features)):\n",
    "    violinPlot(i, numerical_features,numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of information given from each plot: \n",
    "1. `Elevation` - takes on a wide range of values and classes. All of the classes are covered by the elevations. Most of the elevations between 2000m - 2500m belongs to class 3. Class 7 takes on the maximum value of ~4000m. One can also see that most of the highest elevations belongs to class 7. Class 7 has a broad range of elevations from roughly ~2700m to ~4000m.\n",
    "2. `Aspect` has a normal distributions for each given class.\n",
    "3. `Slope` is the features which takes on the fewest values and is measured in degrees. \n",
    "4. `Horizontal_distance_To_Hydrology` all values will have a range between 0m - 50m.\n",
    "5. `Vertical_distance_To_Hydrology` all the values varies from ~ -150m to 600m. This feature has the lowest minimum of all the features which belongs to class 2. This means that class 2 has the widest range of observations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wild_data_cols = wild_df.columns\n",
    "\n",
    "for i in range(0, len(wild_data_cols)):\n",
    "    violinPlot(i, wild_df,wild_data_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots looks quite different because the data only contains values of 0 and 1. \n",
    "By looking at the plots one can see: \n",
    "1. `Wilderness_Area1` either belongs to `Cover_Type` 1,2, 5 and 7. \n",
    "2. `Wilderness_Area3` is present in all `Cover_Type` but not in type 3. \n",
    "3. `Wilderness_Area2` has less observations and shows less density on 1. \n",
    "4. `Wilderness_Area4` also has few observations and is more dense at 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "\n",
    "Lets try to find out how correlated the data is. In this section the categorical features will be ignored (because correleation doesn't work that well with non-contionus data :) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# Compute the correlation matrix\n",
    "numerical_features_corr = numerical_features.corr()\n",
    "\n",
    "mask = np.zeros_like(numerical_features_corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "\n",
    "# Generates heatmap masking the upper triangle and shrinking the cbar\n",
    "sns.heatmap(numerical_features_corr, mask=mask, center=0, square=True, annot=True, annot_kws={\"size\": 15}, cbar_kws={\"shrink\": .8})\n",
    "\n",
    "# x-axis label size\n",
    "plt.xticks(size = 13)\n",
    "# y-axis label size\n",
    "plt.yticks(size = 13)\n",
    "\n",
    "# display plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the colors:\n",
    "- The features which are colored black have less or no correlation.\n",
    "- The boxes which are colored orange have high and positive correlation\n",
    "- The blue boxes has negative correlation\n",
    "\n",
    "The less the values are correleated the more valuable information does the feature have to tell our model. Therefore these features are important for the predictions made by the model. \n",
    "\n",
    "Observations: \n",
    "- `Hillside_noon` and `Hillshade_3pm`,  `Hillshade_3pm` and `Aspect` and `Vertical_Distance_To_Hydrololgy` and `Horizontal_Distance_To_Hydrololgy` are highly correleated. \n",
    "\n",
    "Now we can plot the correlations which are higher than 0.5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bg\n",
    "sns.set_style(\"darkgrid\", {'grid.color': '.1'})\n",
    "\n",
    "# giving list of lists\n",
    "# inner lists conatains pairs of feature which have high correlation\n",
    "list_df_corr = [['Aspect','Hillshade_3pm'], ['Aspect', 'Hillshade_9am'], ['Slope', 'Hillshade_Noon'], ['Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology'], \n",
    "                 ['Hillshade_3pm', 'Hillshade_9am'], ['Hillshade_3pm', 'Hillshade_Noon']]\n",
    "\n",
    "\n",
    "# Looping through outer list\n",
    "# taking 2 features from inner list\n",
    "for i,j in list_df_corr:\n",
    "    \n",
    "    # fig size\n",
    "    plt.subplots(figsize=(15, 12))\n",
    "    \n",
    "    #plot 1 feature on x axis and other on y axis, each point shows which cover forest they belong to\n",
    "    sns.scatterplot(data = df, x = i, y = j, hue=\"class\", legend = 'full', palette='pastel')\n",
    "\n",
    "    # x-axis label size\n",
    "    plt.xticks(size = 15)\n",
    "    # y-axis label size\n",
    "    plt.yticks(size = 15)\n",
    "\n",
    "    # Horizontal axis Label\n",
    "    plt.xlabel(i, size = 17)\n",
    "    # Vertical axis Label\n",
    "    plt.ylabel(j, size = 17)\n",
    "  \n",
    "    # display plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Hillshade_3pm` and `Aspect`: has the same relationship has a sigmoid function. \n",
    "- `Hillshade_9am` and `Aspect`: In the interval of `Aspect` ranging from 50 - 250 and `Hillshade_9am` between 100 - 250 most of the cover type belongs to class 3.\n",
    "- `Hillshade_Noon` and `Slope`: When `Slope` has the value between 0-30 most of the cover types belongs to class 3, regardless of what the `Hillside_Noon` value is. While higher slope values mostly belongs to classes 1, 5 and 7. \n",
    "- `Vertical_Distance_To_Hydrology` and `Horizontal_Distance_To_Hydrology`  This pattern just looks dope. \n",
    "- `Hillshade_3pm` and `Hillshade_9am`: This has the shape of a quarter of a circle, where most of the points along the border is of the cover type 3.\n",
    "- `Hillshade_Noon` and `Hillshade_3pm`:  This almost has the same shape as above and here also most of the points along the border is of cover type 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=102)\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y_train.astype(str))\n",
    "y_test = le.transform(y_test.astype(str))\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Adding the input layer to model\n",
    "    num_features = X_train.shape[1] \n",
    "    input = layers.InputLayer(input_shape=num_features,)\n",
    "    model.add(input) \n",
    "\n",
    "    # Set the hidden layers:\n",
    "    model.add(Dense(256, activation = \"relu\"))\n",
    "    model.add(Dense(128, activation = \"relu\"))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, activation = \"relu\"))\n",
    "    model.add(Dense(64, activation = \"relu\"))\n",
    "    model.add(Dense(32, activation = \"relu\"))\n",
    "    model.add(Dense(16, activation = \"relu\"))\n",
    "    model.add(Dense(8, activation = \"relu\"))\n",
    "    # Set the output layer:\n",
    "    model.add(Dense(8, activation = \"softmax\"))\n",
    "    opt = Adam(learning_rate = 0.00001145)\n",
    "    model.compile(\n",
    "        loss = \"sparse_categorical_crossentropy\",  \n",
    "        metrics = [\"accuracy\"], \n",
    "        optimizer = opt\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               14080     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 72        \n",
      "=================================================================\n",
      "Total params: 62,208\n",
      "Trainable params: 62,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " logits and labels must have the same first dimension, got logits shape [100,8] and labels shape [700]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-7-a429da9b2c8a>:3) ]] [Op:__inference_train_function_992]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a429da9b2c8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  logits and labels must have the same first dimension, got logits shape [100,8] and labels shape [700]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-7-a429da9b2c8a>:3) ]] [Op:__inference_train_function_992]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model = create_model(X_train)\n",
    "es = EarlyStopping(monitor='accuracy', mode='min', verbose=1, patience=20)\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=100, verbose = 1, validation_split=.3, callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax2 = fig.add_subplot(2, 1, 2)\n",
    "ax2.plot(val_loss)\n",
    "ax2.plot(loss)\n",
    "ax2.set_title('Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.legend(['Validation', 'Train'], loc='upper right')\n",
    "\n",
    "ax1 = fig.add_subplot(2, 1, 1)\n",
    "ax1.plot(val_acc)\n",
    "ax1.plot(acc)\n",
    "ax1.set_title('Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.legend(['Validation', 'Train'], loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}